{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114d7e0b",
   "metadata": {},
   "source": [
    "# Deep Learning Assignment 2 - Part A\n",
    "## CNN for Image Classification\n",
    "\n",
    "This notebook implements and analyzes a CNN model for image classification using PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88be527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from pathlib import Path\n",
    "from model import CNN\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f958a",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration\n",
    "\n",
    "Let's first load and visualize some samples from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root='data/train_split', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='data/val_split', transform=transform)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"\\nClasses: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238935a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images\n",
    "def show_samples(dataset, num_samples=10):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx in range(num_samples):\n",
    "        img, label = dataset[idx]\n",
    "        axes[idx].imshow(img.permute(1, 2, 0))\n",
    "        axes[idx].set_title(dataset.classes[label])\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de1e8f",
   "metadata": {},
   "source": [
    "## 2. Model Architecture\n",
    "\n",
    "Let's create and visualize our CNN model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with default parameters\n",
    "model = CNN(\n",
    "    num_conv_layers=5,\n",
    "    num_filters=32,\n",
    "    filter_size=3,\n",
    "    activation='ReLU',\n",
    "    dense_layer_neurons=64,\n",
    "    batch_norm=True,\n",
    "    dropout_rate=0.3\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Calculate model complexity\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd5b38",
   "metadata": {},
   "source": [
    "## 3. Training Configuration\n",
    "\n",
    "Set up the training configuration and initialize W&B logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c116c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import LitCNN, train_model\n",
    "\n",
    "# Configure training parameters\n",
    "config = {\n",
    "    'num_conv_layers': 5,\n",
    "    'num_filters': 32,\n",
    "    'filter_size': 3,\n",
    "    'activation': 'ReLU',\n",
    "    'dense_layer_neurons': 64,\n",
    "    'learning_rate': 1e-3,\n",
    "    'batch_norm': True,\n",
    "    'dropout_rate': 0.3,\n",
    "    'data_augmentation': True,\n",
    "    'batch_size': 32,\n",
    "    'max_epochs': 10\n",
    "}\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project='da6401_assignment2_partA', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trained_model = train_model(**config)\n",
    "\n",
    "# Close wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7443d1",
   "metadata": {},
   "source": [
    "## 4. Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5aa7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history from wandb\n",
    "api = wandb.Api()\n",
    "run = api.run(f\"{wandb.run.entity}/{wandb.run.project}/{wandb.run.id}\")\n",
    "history = run.history()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train')\n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.title('Loss over time')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train')\n",
    "plt.plot(history['val_acc'], label='Validation')\n",
    "plt.title('Accuracy over time')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d7e73",
   "metadata": {},
   "source": [
    "## 5. Model Complexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1de3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"Results from Part A:\")\n",
    "print(results)\n",
    "\n",
    "# Create a simple visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results)\n",
    "plt.title('Part A Results')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c4a06",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Sweep\n",
    "\n",
    "Now let's perform a hyperparameter sweep to find the best model configuration. We'll use Weights & Biases (wandb) for tracking the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from partA.train import get_sweep_config\n",
    "import wandb\n",
    "\n",
    "# Get the sweep configuration\n",
    "sweep_config = get_sweep_config()\n",
    "print(\"Sweep configuration:\")\n",
    "print(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc8a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project='da6401_assignment2_partA')\n",
    "\n",
    "# Run the agent\n",
    "wandb.agent(sweep_id, function=train_sweep_model, count=20)  # Run 20 different configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a3c73",
   "metadata": {},
   "source": [
    "## 7. Sweep Analysis\n",
    "\n",
    "Let's analyze the results of our hyperparameter sweep to understand which configurations performed best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from partA.sweep_analysis import analyze_sweep\n",
    "import os\n",
    "\n",
    "# Create output directory for analysis plots\n",
    "os.makedirs('sweep_analysis', exist_ok=True)\n",
    "\n",
    "# Run the analysis\n",
    "analyze_sweep(\n",
    "    entity=wandb.run.entity,\n",
    "    project='da6401_assignment2_partA',\n",
    "    sweep_id=sweep_id,\n",
    "    output_dir='sweep_analysis'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ecf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the analysis plots\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"Accuracy vs. Runs:\")\n",
    "display(Image(filename='sweep_analysis/accuracy_vs_runs.png'))\n",
    "\n",
    "print(\"\\nCorrelation Heatmap:\")\n",
    "display(Image(filename='sweep_analysis/correlation_heatmap.png'))\n",
    "\n",
    "print(\"\\nParallel Coordinates Plot:\")\n",
    "display(Image(filename='sweep_analysis/parallel_coordinates.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
